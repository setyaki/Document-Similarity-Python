{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input path directory dataset and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path can be adjusted base on requirement\n",
    "dataset_path = 'D:\\\\Kuliah\\\\Dataset_UU_15'\n",
    "\n",
    "# query path can be adjusted base on requirement\n",
    "query_path = 'D:\\\\Kuliah\\\\query_RUU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing (*fetching*) title processed dataset document `.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Name:\n",
      "['Draf_RUU Pelayanan Publik_15 Juni__processed']\n",
      "Dataset Name:\n",
      "['2008-14_processed', '2008-39_processed', '2009-25_processed', '2009-36_processed', '2009-38_processed', '2009-39_processed', '2011-4_processed', '2014-23_processed', '2014-30_processed', '2017-1_processed', '2019-2_processed', '2019-3_processed', '2020-11_processed', '2020-1_processed', '2020-4_processed']\n"
     ]
    }
   ],
   "source": [
    "#fileName list for indexing\n",
    "\n",
    "import os, glob, re, ntpath #npath for removing parent directory location\n",
    "\n",
    "queryName =[] # list for fetching all of queryName\n",
    "\n",
    "for input_file in glob.glob(os.path.join(query_path, '*.txt')):\n",
    "    input_file = re.sub(r'.txt', '', input_file) #remove .txt string from file for cleaner look\n",
    "    input_file = ntpath.basename(input_file) # fetch only fileName instead all file directory path\n",
    "    queryName.append(input_file) # append all input_file into fileName list\n",
    "\n",
    "print('Query Name:')\n",
    "print(queryName)\n",
    "\n",
    "fileName =[] # list for fetching all of fileName\n",
    "\n",
    "for input_file in glob.glob(os.path.join(dataset_path, '*.txt')):\n",
    "    input_file = re.sub(r'.txt', '', input_file) #remove .txt string from file for cleaner look\n",
    "    input_file = ntpath.basename(input_file) # fetch only fileName instead all file directory path\n",
    "    fileName.append(input_file) # append all input_file into fileName list\n",
    "print('Dataset Name:')\n",
    "print(fileName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create corpus dataset content from all of dataset files\n",
    "all of the content stored into `raw_values` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a corpus\n",
    "import re\n",
    "\n",
    "raw_values = [] # list for fetching all of file document content\n",
    "for input_file in glob.glob(os.path.join(dataset_path, '*.txt')):\n",
    "    with open(input_file, 'r') as txt_doc:\n",
    "        # append all content to a single list 'raw_values'\n",
    "        raw_values.append(re.sub(r'[^A-Za-z]+', ' ',txt_doc.read())) # re.sub for filtering document content removing all char except alphabet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame from list  `fileName, raw_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from 2 list\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe from fileName and raw_values as columns and name it 'title' and 'content'\n",
    "df_raw = pd.DataFrame(list(zip(fileName,raw_values)),columns=['title','content'])\n",
    "\n",
    "df_raw\n",
    "\n",
    "df_raw.to_csv('indexing_doc.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>indonesia</th>\n",
       "      <td>0.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>republik</th>\n",
       "      <td>0.322766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ukraina</th>\n",
       "      <td>0.289899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ministers</th>\n",
       "      <td>0.248484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabinet</th>\n",
       "      <td>0.248484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integratofl</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integrasi</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integral</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentasi</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zota</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4793 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tfidf\n",
       "indonesia      0.470700\n",
       "republik       0.322766\n",
       "ukraina        0.289899\n",
       "ministers      0.248484\n",
       "cabinet        0.248484\n",
       "...                 ...\n",
       "integratofl    0.000000\n",
       "integrasi      0.000000\n",
       "integral       0.000000\n",
       "instrumentasi  0.000000\n",
       "zota           0.000000\n",
       "\n",
       "[4793 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as py\n",
    "\n",
    "# Vectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Learn vocabulary and idf, return term-document matrix\n",
    "# The astype(‘U’) is telling numpy to convert the data to Unicode (essentially a string in python 3)\n",
    "tfidf = vectorizer.fit_transform(df_raw['content'].values.astype('U'))\n",
    "\n",
    "# Array mapping from feature integer indices to feature name\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "# indexing for each term a tfidf score in dataframe from all of dataset (query not yet included)\n",
    "# tfidf[0] is indexing the vector from tfidf\n",
    "# T.todense() is for transpose the array vector and make it into matrix\n",
    "i = 0\n",
    "for i in range(tfidf.shape[0]): #the [0] index in tfidf is the document index instead of content\n",
    "    df_tfidf= pd.DataFrame(tfidf[i].T.todense(), index= words, columns= [\"tfidf\"])\n",
    "\n",
    "# sorting by the highest TFIDF score in dataframe for knowing the most valuable term in dataset \n",
    "df_tfidf_sorted = df_tfidf.sort_values(by=[\"tfidf\"], ascending=False)\n",
    "\n",
    "# convert and export dataframe df_tfidf_sorted into .csv file\n",
    "df_tfidf_sorted.to_csv('TFIDFraw.csv', encoding='utf-8')\n",
    "\n",
    "df_tfidf_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity query with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity result with query \"Draf_RUU Pelayanan Publik_15 Juni__processed\" :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-25_processed</td>\n",
       "      <td>91.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-38_processed</td>\n",
       "      <td>70.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-4_processed</td>\n",
       "      <td>53.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-14_processed</td>\n",
       "      <td>53.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-11_processed</td>\n",
       "      <td>49.98%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-39_processed</td>\n",
       "      <td>48.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-30_processed</td>\n",
       "      <td>48.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-36_processed</td>\n",
       "      <td>46.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-39_processed</td>\n",
       "      <td>43.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-23_processed</td>\n",
       "      <td>39.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-3_processed</td>\n",
       "      <td>13.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-4_processed</td>\n",
       "      <td>11.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-2_processed</td>\n",
       "      <td>11.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-1_processed</td>\n",
       "      <td>10.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-1_processed</td>\n",
       "      <td>9.21%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Document Similarity\n",
       "2   2009-25_processed     91.90%\n",
       "4   2009-38_processed     70.53%\n",
       "6    2011-4_processed     53.75%\n",
       "0   2008-14_processed     53.41%\n",
       "12  2020-11_processed     49.98%\n",
       "5   2009-39_processed     48.67%\n",
       "8   2014-30_processed     48.38%\n",
       "3   2009-36_processed     46.94%\n",
       "1   2008-39_processed     43.05%\n",
       "7   2014-23_processed     39.55%\n",
       "11   2019-3_processed     13.57%\n",
       "14   2020-4_processed     11.41%\n",
       "10   2019-2_processed     11.28%\n",
       "13   2020-1_processed     10.55%\n",
       "9    2017-1_processed      9.21%"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of using fit_transform, you need to first fit \n",
    "# the new document to the TFIDF matrix corpus like this:\n",
    "queryTFIDF = TfidfVectorizer().fit(words)\n",
    "\n",
    "# create query_value from processed query doc txt (store query content into query_value variable)\n",
    "query_value=[]\n",
    "\n",
    "for query_file in glob.glob(os.path.join(query_path, '*.txt')):\n",
    "    with open(query_file, 'r') as txt_doc:\n",
    "        # append all content to a single list 'raw_values'\n",
    "        query_value.append(re.sub(r'[^A-Za-z]+', ' ',txt_doc.read())) # re.sub for filtering document content removing all char except alphabet\n",
    "\n",
    "# Now we can 'transform' this vector into that matrix shape by using the transform function:\n",
    "queryTFIDF = queryTFIDF.transform(query_value)\n",
    "\n",
    "# As we transformed our query in a tfidf object\n",
    "# we can calculate the cosine similarity in comparison with \n",
    "# our pevious corpora\n",
    "cosine_similarities = cosine_similarity(queryTFIDF, tfidf).flatten() *100 # 100 will make it a percentage\n",
    "\n",
    "# create final dataframe from combination of 2 list (fileName and cosine_similarities) with columns (Document and Similarity)\n",
    "df_final = pd.DataFrame(list(zip(fileName,cosine_similarities)),columns=['Document','Similarity'])\n",
    "\n",
    "# define new dataframe variable = final_similarities, it use to store sorting descending result from similarity column\n",
    "final_similarities = df_final.sort_values(by=['Similarity'], ascending=False) #sort similarity value in descending order\n",
    "final_similarities['Similarity'] = [ '%.2f' % elem for elem in final_similarities['Similarity'] ] #limiting floating number into 2 decimal only for more eligible in Similarity column\n",
    "final_similarities['Similarity']=final_similarities['Similarity'] + '%' # adding '%' symbol into the end of similarity number\n",
    "\n",
    "# convert and export dataframe final_similarities into .csv file\n",
    "final_similarities.to_csv('TFIDFcosineSimilarityResult.csv', encoding='utf-8')\n",
    "\n",
    "# Function to convert list into string \n",
    "def listToString(s): \n",
    "    # initialize an empty string\n",
    "    str1 = \" \"  \n",
    "    # return string  \n",
    "    return (str1.join(s))\n",
    "\n",
    "print('Similarity result with query \"'+listToString(queryName)+'\" :')\n",
    "\n",
    "final_similarities\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e2a41ee26140e8f6a8c80fa87677d2b7090722c5c93db62bf0fbe891b6fc330"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
